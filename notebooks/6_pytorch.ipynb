{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook predicts the `beer_style` using a neural network on the PyTorch\n",
    "framework. It is a modification of the 5_pytorch.ipynb notebook. After 20\n",
    "epochs, there seems to be still some room for improvement.\n",
    "\n",
    "The same model is trained again for 60 more epochs.\n",
    "\n",
    "## Summary\n",
    "The increase of neurons has improved the model performance. The\n",
    "[classification report](#Classification-report) shows that the validation\n",
    "accuracy increased to 31.7%, and the test accuracy increased to 32%. Perhaps\n",
    "training to more epochs would further increase the accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "artefact_prefix = '6_pytorch'\n",
    "target = 'beer_style'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from joblib import dump, load\n",
    "\n",
    "from src.data.sets import merge_categories\n",
    "from src.data.sets import save_sets\n",
    "from src.data.sets import load_sets\n",
    "from src.data.sets import split_sets_random\n",
    "from src.data.sets import test_class_exclusion\n",
    "from src.models.performance import convert_cr_to_dataframe\n",
    "from src.models.pytorch import PytorchClassification_5\n",
    "from src.models.pytorch import get_device\n",
    "from src.models.pytorch import train_classification\n",
    "from src.models.pytorch import test_classification\n",
    "from src.models.pytorch import PytorchDataset\n",
    "from src.models.pipes import create_preprocessing_pipe\n",
    "from src.visualization.visualize import plot_confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set up directories"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "project_dir = Path(find_dotenv()).parent\n",
    "data_dir = project_dir / 'data'\n",
    "raw_data_dir = data_dir / 'raw'\n",
    "interim_data_dir = data_dir / 'interim'\n",
    "processed_data_dir = data_dir / 'processed'\n",
    "reports_dir = project_dir / 'reports'\n",
    "models_dir = project_dir / 'models'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Set directory\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = load_sets()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess data\n",
    "\n",
    "1. The `brewery_name` is a feature with a very high cardinality, ~5700. One hot\n",
    " encoding is not feasible as it will introduce 5700 very sparse columns.\n",
    " Another option is to use binary encoding, which would result in 14 new columns.\n",
    "1. Standard scaling is used to ensure that the binary columns ([0, 1])and the\n",
    "review columns ([1, 5]) are on the same scale."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('bin_encoder', BinaryEncoder(cols=['brewery_name'])),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train_trans = pipe.fit_transform(X_train)\n",
    "X_val_trans = pipe.transform(X_val)\n",
    "X_test_trans = pipe.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(951968, 18)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "18"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X_train_trans.shape[1]\n",
    "n_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "104"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = y_train.nunique()\n",
    "n_classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoding\n",
    "\n",
    "PyTorch accepts only numerical labels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roger\\.conda\\envs\\adsi_ass_2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Roger\\.conda\\envs\\adsi_ass_2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_trans = le.fit_transform(y_train.to_frame())\n",
    "y_val_trans = le.fit_transform(y_val.to_frame())\n",
    "y_test_trans = le.transform(y_test.to_frame())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([98, 89,  2, ..., 37, 94, 98])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_trans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to Pytorch tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device()\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train_dataset = PytorchDataset(X=X_train_trans, y=y_train_trans)\n",
    "val_dataset = PytorchDataset(X=X_val_trans, y=y_val_trans)\n",
    "test_dataset = PytorchDataset(X=X_test_trans, y=y_test_trans)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification model\n",
    "\n",
    "Load from the previous experiment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "PytorchClassification_5(\n  (layer_1): Linear(in_features=18, out_features=2048, bias=True)\n  (batchnorm1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer_2): Linear(in_features=2048, out_features=512, bias=True)\n  (batchnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer_3): Linear(in_features=512, out_features=256, bias=True)\n  (batchnorm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer_4): Linear(in_features=256, out_features=64, bias=True)\n  (batchnorm4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer_out): Linear(in_features=64, out_features=104, bias=True)\n  (relu): ReLU()\n  (dropout): Dropout(p=0.2, inplace=False)\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(models_dir / '5_pytorch_model.torch')\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "N_EPOCHS = 60\n",
    "BATCH_SIZE = 2048\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: 2021-03-13 16:45:07.274236\n",
      "Epoch: 0\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 1\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 2\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.2%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 3\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 4\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 5\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 6\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 7\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 8\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.8%\n",
      "Epoch: 9\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 10\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.2%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 11\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.2%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 12\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 13\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 14\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.8%\n",
      "Epoch: 15\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 16\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 17\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 18\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 19\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 20\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 21\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 22\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 23\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 24\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.2%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 25\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 26\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 27\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 28\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 29\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 30\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 31\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.2%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 32\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.8%\n",
      "Epoch: 33\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 34\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 35\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 36\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 37\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 38\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 39\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.2%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 40\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 41\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 42\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.2%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 43\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.8%\n",
      "Epoch: 44\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.2%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 45\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 46\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 47\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.2%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 48\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 49\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 50\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.8%\n",
      "Epoch: 51\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 52\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 53\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 54\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 55\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 56\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 57\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.4%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.8%\n",
      "Epoch: 58\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Epoch: 59\n",
      "\t(train)\tLoss: 0.0012\t|\tAcc: 30.3%\n",
      "\t(valid)\tLoss: 0.0011\t|\tAcc: 31.7%\n",
      "Ended: 2021-03-13 17:00:02.558013\n",
      "Runtime: 0:14:55.283777\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(f'Started: {start_time}')\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion, \n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device,\n",
    "                                                 scheduler=scheduler)\n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion, \n",
    "                                                batch_size=BATCH_SIZE, \n",
    "                                                device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')\n",
    "\n",
    "end_time = datetime.now()\n",
    "runtime = end_time - start_time\n",
    "print(f'Ended: {end_time}')\n",
    "print(f'Runtime: {runtime}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "PytorchClassification_5(\n  (layer_1): Linear(in_features=18, out_features=2048, bias=True)\n  (batchnorm1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer_2): Linear(in_features=2048, out_features=512, bias=True)\n  (batchnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer_3): Linear(in_features=512, out_features=256, bias=True)\n  (batchnorm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer_4): Linear(in_features=256, out_features=64, bias=True)\n  (batchnorm4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer_out): Linear(in_features=64, out_features=104, bias=True)\n  (relu): ReLU()\n  (dropout): Dropout(p=0.2, inplace=False)\n)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the CPU version if the GPU runs out of memory.\n",
    "# preds = model(test_dataset.X_tensor.to(device)).argmax(1)\n",
    "model.to('cpu')\n",
    "preds = model(test_dataset.X_tensor).argmax(1)\n",
    "preds\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roger\\.conda\\envs\\adsi_ass_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "                            Altbier       0.35      0.40      0.37      1521\n",
      "             American Adjunct Lager       0.58      0.75      0.65      6085\n",
      "           American Amber / Red Ale       0.20      0.24      0.22      9288\n",
      "         American Amber / Red Lager       0.30      0.36      0.32      1887\n",
      "                American Barleywine       0.26      0.03      0.06      5390\n",
      "                 American Black Ale       0.42      0.06      0.10      2394\n",
      "                American Blonde Ale       0.30      0.07      0.11      2594\n",
      "                 American Brown Ale       0.25      0.09      0.13      5066\n",
      "            American Dark Wheat Ale       0.00      0.00      0.00       296\n",
      "     American Double / Imperial IPA       0.27      0.37      0.31     17159\n",
      " American Double / Imperial Pilsner       0.21      0.01      0.02      1109\n",
      "   American Double / Imperial Stout       0.36      0.47      0.41     10187\n",
      "                       American IPA       0.21      0.50      0.30     23356\n",
      "               American Malt Liquor       0.75      0.24      0.36       759\n",
      "            American Pale Ale (APA)       0.20      0.21      0.21     12479\n",
      "                American Pale Lager       0.42      0.26      0.32      1871\n",
      "            American Pale Wheat Ale       0.20      0.18      0.19      4900\n",
      "                    American Porter       0.25      0.22      0.24     10097\n",
      "                     American Stout       0.22      0.35      0.27      4966\n",
      "                American Strong Ale       0.26      0.44      0.32      6335\n",
      "                  American Wild Ale       0.30      0.40      0.34      3494\n",
      "                      Baltic Porter       0.45      0.44      0.44      2322\n",
      "                   Belgian Dark Ale       0.13      0.06      0.08      1278\n",
      "                        Belgian IPA       0.39      0.16      0.22      2428\n",
      "                   Belgian Pale Ale       0.48      0.27      0.35      3954\n",
      "            Belgian Strong Dark Ale       0.41      0.40      0.40      7511\n",
      "            Belgian Strong Pale Ale       0.42      0.29      0.35      6181\n",
      "                 Berliner Weissbier       0.43      0.24      0.31       712\n",
      "    Bière de Champagne / Bière Brut       0.25      0.03      0.05       211\n",
      "                     Bière de Garde       0.44      0.42      0.43      1340\n",
      "                        Black & Tan       0.40      0.17      0.24       459\n",
      "                               Bock       0.12      0.27      0.17      2323\n",
      "                            Braggot       0.29      0.11      0.16       207\n",
      "     California Common / Steam Beer       0.23      0.26      0.25       809\n",
      "                         Chile Beer       0.69      0.19      0.30       496\n",
      "                          Cream Ale       0.25      0.17      0.20      1052\n",
      "                     Czech Pilsener       0.63      0.37      0.47      2484\n",
      "                         Doppelbock       0.45      0.33      0.38      4380\n",
      "          Dortmunder / Export Lager       0.23      0.25      0.24       928\n",
      "                             Dubbel       0.37      0.16      0.22      4036\n",
      "                       Dunkelweizen       0.40      0.02      0.03      1426\n",
      "                            Eisbock       0.25      0.26      0.25       506\n",
      "                 English Barleywine       0.55      0.18      0.27      2798\n",
      "                     English Bitter       0.26      0.25      0.26      1783\n",
      "                  English Brown Ale       0.38      0.28      0.32      3870\n",
      "              English Dark Mild Ale       0.64      0.11      0.19       482\n",
      "       English India Pale Ale (IPA)       0.26      0.17      0.21      3218\n",
      "                   English Pale Ale       0.42      0.47      0.45      4631\n",
      "              English Pale Mild Ale       0.00      0.00      0.00       135\n",
      "                     English Porter       0.38      0.23      0.29      2225\n",
      "                      English Stout       0.34      0.16      0.22       605\n",
      "                 English Strong Ale       0.34      0.17      0.23       982\n",
      "                    Euro Dark Lager       0.32      0.19      0.24       916\n",
      "                    Euro Pale Lager       0.63      0.72      0.67      3673\n",
      "                  Euro Strong Lager       0.51      0.26      0.35       542\n",
      "Extra Special / Strong Bitter (ESB)       0.26      0.15      0.19      3539\n",
      "                               Faro       0.00      0.00      0.00       117\n",
      "                 Flanders Oud Bruin       0.40      0.20      0.27       944\n",
      "                   Flanders Red Ale       0.77      0.63      0.69      1332\n",
      "             Foreign / Export Stout       0.44      0.42      0.43      1185\n",
      "             Fruit / Vegetable Beer       0.27      0.41      0.33      6710\n",
      "                    German Pilsener       0.47      0.32      0.38      4416\n",
      "                               Gose       0.59      0.64      0.62       119\n",
      "                             Gueuze       0.65      0.37      0.47      1206\n",
      "                           Happoshu       0.29      0.09      0.13        46\n",
      "                         Hefeweizen       0.38      0.31      0.34      5675\n",
      "               Herbed / Spiced Beer       0.36      0.07      0.12      2081\n",
      "                    Irish Dry Stout       0.62      0.53      0.57      2537\n",
      "                      Irish Red Ale       0.51      0.13      0.21      1572\n",
      "                Japanese Rice Lager       0.69      0.88      0.77       308\n",
      "         Keller Bier / Zwickel Bier       0.43      0.20      0.27       525\n",
      "                      Kristalweizen       0.18      0.04      0.07       426\n",
      "                              Kvass       0.62      0.49      0.55        63\n",
      "                             Kölsch       0.48      0.23      0.31      1678\n",
      "                     Lambic - Fruit       0.57      0.74      0.64      2152\n",
      "                 Lambic - Unblended       0.60      0.08      0.14       227\n",
      "                        Light Lager       0.49      0.50      0.49      2759\n",
      "                   Low Alcohol Beer       0.48      0.05      0.08       222\n",
      "              Maibock / Helles Bock       0.19      0.10      0.13      2087\n",
      "                 Milk / Sweet Stout       0.30      0.47      0.37      2623\n",
      "                Munich Dunkel Lager       0.35      0.21      0.26      1566\n",
      "                Munich Helles Lager       0.41      0.12      0.19      1600\n",
      "               Märzen / Oktoberfest       0.31      0.14      0.19      4777\n",
      "                      Oatmeal Stout       0.27      0.26      0.27      3646\n",
      "                            Old Ale       0.47      0.25      0.33      2927\n",
      "                        Pumpkin Ale       0.34      0.15      0.21      3122\n",
      "                   Quadrupel (Quad)       0.43      0.43      0.43      3737\n",
      "                          Rauchbier       0.68      0.55      0.61       817\n",
      "                         Roggenbier       0.41      0.20      0.27       101\n",
      "             Russian Imperial Stout       0.32      0.43      0.37     10792\n",
      "                           Rye Beer       0.30      0.18      0.23      2054\n",
      "                              Sahti       0.91      0.21      0.34       198\n",
      "             Saison / Farmhouse Ale       0.41      0.44      0.42      6327\n",
      "                        Schwarzbier       0.35      0.33      0.34      1956\n",
      "             Scotch Ale / Wee Heavy       0.41      0.20      0.27      3460\n",
      "                       Scottish Ale       0.36      0.34      0.35      1827\n",
      "Scottish Gruit / Ancient Herbed Ale       0.85      0.76      0.80       557\n",
      "                        Smoked Beer       0.08      0.00      0.00       556\n",
      "                             Tripel       0.32      0.20      0.25      6074\n",
      "                       Vienna Lager       0.15      0.08      0.10      1865\n",
      "                         Weizenbock       0.57      0.29      0.38      1922\n",
      "                          Wheatwine       0.00      0.00      0.00       731\n",
      "                      Winter Warmer       0.29      0.19      0.23      4130\n",
      "                            Witbier       0.33      0.22      0.26      5896\n",
      "\n",
      "                           accuracy                           0.32    317323\n",
      "                          macro avg       0.38      0.27      0.29    317323\n",
      "                       weighted avg       0.34      0.32      0.31    317323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, le.inverse_transform(preds.cpu()))\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save objects for production"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "path = models_dir / f'{artefact_prefix}_model'\n",
    "torch.save(model, path.with_suffix('.torch'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create pipe object\n",
    "\n",
    "This is for transforming the input prior to prediction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "['D:\\\\git\\\\assignment_2\\\\models\\\\6_pytorch_pipe.sav']"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X_train, X_val, X_test])\n",
    "prod_pipe = create_preprocessing_pipe(X)\n",
    "\n",
    "path = models_dir / f'{artefact_prefix}_pipe'\n",
    "dump(prod_pipe, path.with_suffix('.sav'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save `LabelEncoder`\n",
    "\n",
    "This is required to get back the name of the name of the `beer_style`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "['D:\\\\git\\\\assignment_2\\\\models\\\\6_pytorch_label_encoder.sav']"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = models_dir / f'{artefact_prefix}_label_encoder'\n",
    "dump(le, path.with_suffix('.sav'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "adsi_ass_2",
   "language": "python",
   "display_name": "adsi_ass_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}