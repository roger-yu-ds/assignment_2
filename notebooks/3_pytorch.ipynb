{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook predicts the `beer_style` using a neural network on the PyTorch\n",
    "framework. This notebook uses a more complex version of `2_pytorch`.\n",
    "\n",
    "## Summary\n",
    "The [classification report](#Classification-report) shows that\n",
    "* the test accuracy is 30%, while the validation accuracy is also around 30%,\n",
    "hence there doesn't seem to be overfitting\n",
    "* the [top 10 classes by number of observations](#Top-10-by-number-of-observations)\n",
    " don't have high f1-scores.\n",
    "* the [top 10 classes by f1-score](#Top-10-by-f1-score) have very few\n",
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "artefact_prefix = '3_pytorch'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from joblib import dump, load\n",
    "\n",
    "from src.data.sets import save_sets\n",
    "from src.data.sets import load_sets\n",
    "from src.data.sets import split_sets_random\n",
    "from src.data.sets import test_class_exclusion\n",
    "from src.models.performance import convert_cr_to_dataframe\n",
    "from src.models.pytorch import PytorchClassification_3\n",
    "from src.models.pytorch import get_device\n",
    "from src.models.pytorch import train_classification\n",
    "from src.models.pytorch import test_classification\n",
    "from src.models.pytorch import PytorchDataset\n",
    "from src.models.pipes import create_preprocessing_pipe\n",
    "from src.visualization.visualize import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Set directory\n"
    }
   },
   "outputs": [],
   "source": [
    "project_dir = Path.cwd().parent\n",
    "data_dir = project_dir / 'data'\n",
    "raw_data_dir = data_dir / 'raw'\n",
    "interim_data_dir = data_dir / 'interim'\n",
    "processed_data_dir = data_dir / 'processed'\n",
    "reports_dir = project_dir / 'reports'\n",
    "models_dir = project_dir / 'models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Load data\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = load_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "American IPA                        0.074216\nAmerican Double / Imperial IPA      0.054196\nAmerican Pale Ale (APA)             0.040204\nRussian Imperial Stout              0.034057\nAmerican Double / Imperial Stout    0.031940\n                                      ...   \nGose                                0.000444\nFaro                                0.000378\nRoggenbier                          0.000297\nKvass                               0.000189\nHapposhu                            0.000136\nName: beer_style, Length: 104, dtype: float64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "American IPA                        0.074306\nAmerican Double / Imperial IPA      0.054282\nAmerican Pale Ale (APA)             0.040076\nRussian Imperial Stout              0.034400\nAmerican Double / Imperial Stout    0.031867\n                                      ...   \nEnglish Pale Mild Ale               0.000432\nFaro                                0.000416\nRoggenbier                          0.000258\nHapposhu                            0.000208\nKvass                               0.000170\nName: beer_style, Length: 104, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "American IPA                        0.073603\nAmerican Double / Imperial IPA      0.054074\nAmerican Pale Ale (APA)             0.039326\nRussian Imperial Stout              0.034010\nAmerican Double / Imperial Stout    0.032103\n                                      ...   \nGose                                0.000375\nFaro                                0.000369\nRoggenbier                          0.000318\nKvass                               0.000199\nHapposhu                            0.000145\nName: beer_style, Length: 104, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                              brewery_name  review_aroma  review_appearance  \\\n0           Kirin Brewery Company, Limited           1.5                3.0   \n1              Huisbrouwerij Klein Duimpje           3.0                4.0   \n2                Southampton Publick House           3.0                3.5   \n3         Rock Bottom Restaurant & Brewery           3.5                4.0   \n4       Boston Beer Company (Samuel Adams)           4.0                3.5   \n...                                    ...           ...                ...   \n951963  Bierbrouwerij Sint Christoffel B.V           4.5                4.0   \n951964              Brouwerij Slaghmuylder           3.5                4.0   \n951965         Thirsty Dog Brewing Company           4.0                4.0   \n951966        OPA-OPA Steakhouse & Brewery           4.0                3.5   \n951967                       Mikkeller ApS           4.0                4.5   \n\n        review_palate  review_taste  \n0                 3.0           3.5  \n1                 3.5           3.5  \n2                 4.0           3.5  \n3                 2.5           3.5  \n4                 3.5           3.5  \n...               ...           ...  \n951963            4.0           4.0  \n951964            3.5           4.0  \n951965            4.0           4.5  \n951966            3.0           4.0  \n951967            4.0           3.5  \n\n[951968 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brewery_name</th>\n      <th>review_aroma</th>\n      <th>review_appearance</th>\n      <th>review_palate</th>\n      <th>review_taste</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kirin Brewery Company, Limited</td>\n      <td>1.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Huisbrouwerij Klein Duimpje</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Southampton Publick House</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Rock Bottom Restaurant &amp; Brewery</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>2.5</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Boston Beer Company (Samuel Adams)</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>951963</th>\n      <td>Bierbrouwerij Sint Christoffel B.V</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>951964</th>\n      <td>Brouwerij Slaghmuylder</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>951965</th>\n      <td>Thirsty Dog Brewing Company</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>951966</th>\n      <td>OPA-OPA Steakhouse &amp; Brewery</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>951967</th>\n      <td>Mikkeller ApS</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>951968 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for excluded classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'✔ All the sets contain all the classes.'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_class_exclusion(y_train, y_test, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "\n",
    "1. The `brewery_name` is a feature with a very high cardinality, ~5700. One hot encoding is not feasible as it will introduce 5700 very sparse columns. Another option is to use binary encoding, which would result in 14 new columns.\n",
    "1. Standard scaling is used to ensure that the binary columns ([0, 1])and the review columns ([1, 5]) are on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('bin_encoder', BinaryEncoder(cols=['brewery_name'])),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = pipe.fit_transform(X_train)\n",
    "X_val_trans = pipe.transform(X_val)\n",
    "X_test_trans = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(951968, 18)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "18"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X_train_trans.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "104"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = y_train.nunique()\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoding\n",
    "\n",
    "PyTorch accepts only numerical labels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roger\\.conda\\envs\\adsi_ass_2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Roger\\.conda\\envs\\adsi_ass_2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_trans = le.fit_transform(y_train.to_frame())\n",
    "y_val_trans = le.fit_transform(y_val.to_frame())\n",
    "y_test_trans = le.transform(y_test.to_frame())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([98, 89,  2, ..., 37, 94, 98])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_trans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to Pytorch tensors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device()\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "train_dataset = PytorchDataset(X=X_train_trans, y=y_train_trans)\n",
    "val_dataset = PytorchDataset(X=X_val_trans, y=y_val_trans)\n",
    "test_dataset = PytorchDataset(X=X_test_trans, y=y_test_trans)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PytorchClassification_3(n_features=n_features, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "PytorchClassification_3(\n  (layer_1): Linear(in_features=18, out_features=512, bias=True)\n  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer_2): Linear(in_features=512, out_features=128, bias=True)\n  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer_out): Linear(in_features=64, out_features=104, bias=True)\n  (relu): ReLU()\n  (dropout): Dropout(p=0.2, inplace=False)\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 20\n",
    "BATCH_SIZE = 512\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "start_time = datetime.now()\n",
    "print(f'Started: {start_time}')\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion, \n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device,\n",
    "                                                 scheduler=scheduler)\n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion, \n",
    "                                                batch_size=BATCH_SIZE, \n",
    "                                                device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')\n",
    "\n",
    "end_time = datetime.now()\n",
    "runtime = end_time - start_time\n",
    "print(f'Ended: {end_time}')\n",
    "print(f'Runtime: {runtime}')\n"
   ],
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: 2021-03-12 16:20:13.922325\n",
      "Epoch: 0\n",
      "\t(train)\tLoss: 0.0064\t|\tAcc: 19.5%\n",
      "\t(valid)\tLoss: 0.0055\t|\tAcc: 25.9%\n",
      "Epoch: 1\n",
      "\t(train)\tLoss: 0.0057\t|\tAcc: 23.7%\n",
      "\t(valid)\tLoss: 0.0053\t|\tAcc: 27.0%\n",
      "Epoch: 2\n",
      "\t(train)\tLoss: 0.0056\t|\tAcc: 24.6%\n",
      "\t(valid)\tLoss: 0.0051\t|\tAcc: 27.8%\n",
      "Epoch: 3\n",
      "\t(train)\tLoss: 0.0055\t|\tAcc: 25.1%\n",
      "\t(valid)\tLoss: 0.0051\t|\tAcc: 28.2%\n",
      "Epoch: 4\n",
      "\t(train)\tLoss: 0.0054\t|\tAcc: 25.4%\n",
      "\t(valid)\tLoss: 0.0050\t|\tAcc: 28.2%\n",
      "Epoch: 5\n",
      "\t(train)\tLoss: 0.0054\t|\tAcc: 25.7%\n",
      "\t(valid)\tLoss: 0.0050\t|\tAcc: 28.5%\n",
      "Epoch: 6\n",
      "\t(train)\tLoss: 0.0053\t|\tAcc: 25.9%\n",
      "\t(valid)\tLoss: 0.0050\t|\tAcc: 28.6%\n",
      "Epoch: 7\n",
      "\t(train)\tLoss: 0.0053\t|\tAcc: 26.0%\n",
      "\t(valid)\tLoss: 0.0049\t|\tAcc: 28.8%\n",
      "Epoch: 8\n",
      "\t(train)\tLoss: 0.0053\t|\tAcc: 26.1%\n",
      "\t(valid)\tLoss: 0.0049\t|\tAcc: 29.0%\n",
      "Epoch: 9\n",
      "\t(train)\tLoss: 0.0053\t|\tAcc: 26.2%\n",
      "\t(valid)\tLoss: 0.0049\t|\tAcc: 29.0%\n",
      "Epoch: 10\n",
      "\t(train)\tLoss: 0.0052\t|\tAcc: 26.4%\n",
      "\t(valid)\tLoss: 0.0049\t|\tAcc: 29.1%\n",
      "Epoch: 11\n",
      "\t(train)\tLoss: 0.0052\t|\tAcc: 26.5%\n",
      "\t(valid)\tLoss: 0.0049\t|\tAcc: 29.2%\n",
      "Epoch: 12\n",
      "\t(train)\tLoss: 0.0052\t|\tAcc: 26.6%\n",
      "\t(valid)\tLoss: 0.0049\t|\tAcc: 29.3%\n",
      "Epoch: 13\n",
      "\t(train)\tLoss: 0.0052\t|\tAcc: 26.7%\n",
      "\t(valid)\tLoss: 0.0049\t|\tAcc: 29.4%\n",
      "Epoch: 14\n",
      "\t(train)\tLoss: 0.0052\t|\tAcc: 26.7%\n",
      "\t(valid)\tLoss: 0.0048\t|\tAcc: 29.3%\n",
      "Epoch: 15\n",
      "\t(train)\tLoss: 0.0052\t|\tAcc: 26.7%\n",
      "\t(valid)\tLoss: 0.0048\t|\tAcc: 29.5%\n",
      "Epoch: 16\n",
      "\t(train)\tLoss: 0.0052\t|\tAcc: 26.9%\n",
      "\t(valid)\tLoss: 0.0048\t|\tAcc: 29.5%\n",
      "Epoch: 17\n",
      "\t(train)\tLoss: 0.0052\t|\tAcc: 26.9%\n",
      "\t(valid)\tLoss: 0.0048\t|\tAcc: 29.4%\n",
      "Epoch: 18\n",
      "\t(train)\tLoss: 0.0052\t|\tAcc: 26.9%\n",
      "\t(valid)\tLoss: 0.0048\t|\tAcc: 29.6%\n",
      "Epoch: 19\n",
      "\t(train)\tLoss: 0.0052\t|\tAcc: 27.0%\n",
      "\t(valid)\tLoss: 0.0048\t|\tAcc: 29.6%\n",
      "Ended: 2021-03-12 16:28:14.234004\n",
      "Runtime: 0:08:00.311679\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([25, 18,  9,  ..., 65, 47, 25], device='cuda:0')"
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(test_dataset.X_tensor.to(device)).argmax(1)\n",
    "preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roger\\.conda\\envs\\adsi_ass_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "                            Altbier       0.35      0.34      0.35      1521\n",
      "             American Adjunct Lager       0.53      0.73      0.62      6085\n",
      "           American Amber / Red Ale       0.19      0.22      0.20      9288\n",
      "         American Amber / Red Lager       0.31      0.32      0.31      1887\n",
      "                American Barleywine       0.24      0.01      0.03      5390\n",
      "                 American Black Ale       0.40      0.05      0.08      2394\n",
      "                American Blonde Ale       0.22      0.01      0.02      2594\n",
      "                 American Brown Ale       0.26      0.08      0.12      5066\n",
      "            American Dark Wheat Ale       0.00      0.00      0.00       296\n",
      "     American Double / Imperial IPA       0.25      0.36      0.30     17159\n",
      " American Double / Imperial Pilsner       0.00      0.00      0.00      1109\n",
      "   American Double / Imperial Stout       0.34      0.46      0.39     10187\n",
      "                       American IPA       0.18      0.52      0.27     23356\n",
      "               American Malt Liquor       0.88      0.20      0.33       759\n",
      "            American Pale Ale (APA)       0.16      0.21      0.18     12479\n",
      "                American Pale Lager       0.45      0.21      0.28      1871\n",
      "            American Pale Wheat Ale       0.17      0.15      0.16      4900\n",
      "                    American Porter       0.23      0.22      0.22     10097\n",
      "                     American Stout       0.21      0.28      0.24      4966\n",
      "                American Strong Ale       0.25      0.43      0.32      6335\n",
      "                  American Wild Ale       0.31      0.36      0.34      3494\n",
      "                      Baltic Porter       0.48      0.40      0.43      2322\n",
      "                   Belgian Dark Ale       0.11      0.01      0.02      1278\n",
      "                        Belgian IPA       0.39      0.17      0.23      2428\n",
      "                   Belgian Pale Ale       0.62      0.23      0.33      3954\n",
      "            Belgian Strong Dark Ale       0.41      0.37      0.39      7511\n",
      "            Belgian Strong Pale Ale       0.41      0.29      0.34      6181\n",
      "                 Berliner Weissbier       0.74      0.17      0.27       712\n",
      "    Bière de Champagne / Bière Brut       0.09      0.00      0.01       211\n",
      "                     Bière de Garde       0.62      0.36      0.46      1340\n",
      "                        Black & Tan       0.31      0.19      0.23       459\n",
      "                               Bock       0.12      0.28      0.16      2323\n",
      "                            Braggot       0.00      0.00      0.00       207\n",
      "     California Common / Steam Beer       0.23      0.21      0.22       809\n",
      "                         Chile Beer       0.97      0.16      0.27       496\n",
      "                          Cream Ale       0.23      0.13      0.16      1052\n",
      "                     Czech Pilsener       0.68      0.33      0.44      2484\n",
      "                         Doppelbock       0.42      0.31      0.35      4380\n",
      "          Dortmunder / Export Lager       0.76      0.12      0.21       928\n",
      "                             Dubbel       0.37      0.10      0.16      4036\n",
      "                       Dunkelweizen       0.00      0.00      0.00      1426\n",
      "                            Eisbock       0.23      0.32      0.27       506\n",
      "                 English Barleywine       0.65      0.16      0.26      2798\n",
      "                     English Bitter       0.25      0.13      0.17      1783\n",
      "                  English Brown Ale       0.39      0.26      0.31      3870\n",
      "              English Dark Mild Ale       0.52      0.05      0.09       482\n",
      "       English India Pale Ale (IPA)       0.21      0.11      0.14      3218\n",
      "                   English Pale Ale       0.39      0.46      0.42      4631\n",
      "              English Pale Mild Ale       0.00      0.00      0.00       135\n",
      "                     English Porter       0.32      0.26      0.29      2225\n",
      "                      English Stout       0.38      0.05      0.09       605\n",
      "                 English Strong Ale       0.34      0.14      0.20       982\n",
      "                    Euro Dark Lager       0.30      0.05      0.08       916\n",
      "                    Euro Pale Lager       0.50      0.73      0.59      3673\n",
      "                  Euro Strong Lager       0.53      0.10      0.17       542\n",
      "Extra Special / Strong Bitter (ESB)       0.26      0.04      0.07      3539\n",
      "                               Faro       0.00      0.00      0.00       117\n",
      "                 Flanders Oud Bruin       0.40      0.22      0.28       944\n",
      "                   Flanders Red Ale       0.77      0.63      0.70      1332\n",
      "             Foreign / Export Stout       0.41      0.35      0.38      1185\n",
      "             Fruit / Vegetable Beer       0.27      0.35      0.30      6710\n",
      "                    German Pilsener       0.41      0.29      0.34      4416\n",
      "                               Gose       0.58      0.60      0.59       119\n",
      "                             Gueuze       0.68      0.33      0.45      1206\n",
      "                           Happoshu       0.00      0.00      0.00        46\n",
      "                         Hefeweizen       0.38      0.26      0.31      5675\n",
      "               Herbed / Spiced Beer       0.58      0.02      0.05      2081\n",
      "                    Irish Dry Stout       0.65      0.52      0.58      2537\n",
      "                      Irish Red Ale       0.55      0.12      0.20      1572\n",
      "                Japanese Rice Lager       0.62      0.88      0.73       308\n",
      "         Keller Bier / Zwickel Bier       0.40      0.12      0.18       525\n",
      "                      Kristalweizen       0.19      0.01      0.03       426\n",
      "                              Kvass       0.44      0.19      0.27        63\n",
      "                             Kölsch       0.42      0.20      0.27      1678\n",
      "                     Lambic - Fruit       0.55      0.75      0.64      2152\n",
      "                 Lambic - Unblended       0.73      0.07      0.13       227\n",
      "                        Light Lager       0.45      0.52      0.48      2759\n",
      "                   Low Alcohol Beer       0.42      0.06      0.11       222\n",
      "              Maibock / Helles Bock       0.23      0.04      0.07      2087\n",
      "                 Milk / Sweet Stout       0.30      0.47      0.36      2623\n",
      "                Munich Dunkel Lager       0.31      0.12      0.18      1566\n",
      "                Munich Helles Lager       0.40      0.16      0.23      1600\n",
      "               Märzen / Oktoberfest       0.29      0.14      0.19      4777\n",
      "                      Oatmeal Stout       0.28      0.22      0.24      3646\n",
      "                            Old Ale       0.55      0.19      0.28      2927\n",
      "                        Pumpkin Ale       0.31      0.14      0.19      3122\n",
      "                   Quadrupel (Quad)       0.43      0.44      0.44      3737\n",
      "                          Rauchbier       0.74      0.53      0.62       817\n",
      "                         Roggenbier       0.45      0.05      0.09       101\n",
      "             Russian Imperial Stout       0.33      0.39      0.36     10792\n",
      "                           Rye Beer       0.30      0.15      0.20      2054\n",
      "                              Sahti       0.91      0.20      0.32       198\n",
      "             Saison / Farmhouse Ale       0.38      0.42      0.40      6327\n",
      "                        Schwarzbier       0.47      0.26      0.33      1956\n",
      "             Scotch Ale / Wee Heavy       0.34      0.18      0.23      3460\n",
      "                       Scottish Ale       0.40      0.29      0.34      1827\n",
      "Scottish Gruit / Ancient Herbed Ale       0.88      0.76      0.81       557\n",
      "                        Smoked Beer       0.22      0.01      0.01       556\n",
      "                             Tripel       0.33      0.18      0.23      6074\n",
      "                       Vienna Lager       0.14      0.05      0.07      1865\n",
      "                         Weizenbock       0.57      0.30      0.39      1922\n",
      "                          Wheatwine       0.00      0.00      0.00       731\n",
      "                      Winter Warmer       0.30      0.16      0.21      4130\n",
      "                            Witbier       0.30      0.21      0.25      5896\n",
      "\n",
      "                           accuracy                           0.30    317323\n",
      "                          macro avg       0.38      0.23      0.26    317323\n",
      "                       weighted avg       0.33      0.30      0.28    317323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, le.inverse_transform(preds.cpu()))\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roger\\.conda\\envs\\adsi_ass_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(y_test,\n",
    "                                    le.inverse_transform(preds.cpu()),\n",
    "                                    output_dict=True)\n",
    "report_df = convert_cr_to_dataframe(report_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Top 10 by number of observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "data": {
      "text/plain": "                          beer_style  precision    recall        f1  support\n12                      American IPA   0.180058  0.511835  0.266400    23406\n9     American Double / Imperial IPA   0.255797  0.365666  0.301020    17196\n14           American Pale Ale (APA)   0.167338  0.180754  0.173787    12647\n89            Russian Imperial Stout   0.309647  0.404610  0.350816    10630\n17                   American Porter   0.223503  0.207952  0.215447    10161\n11  American Double / Imperial Stout   0.361799  0.448238  0.400407    10104\n2           American Amber / Red Ale   0.171532  0.228809  0.196073     9143\n25           Belgian Strong Dark Ale   0.386467  0.396476  0.391407     7491\n60            Fruit / Vegetable Beer   0.259689  0.334737  0.292476     6886\n19               American Strong Ale   0.241337  0.365169  0.290611     6408",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>beer_style</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>American IPA</td>\n      <td>0.180058</td>\n      <td>0.511835</td>\n      <td>0.266400</td>\n      <td>23406</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>American Double / Imperial IPA</td>\n      <td>0.255797</td>\n      <td>0.365666</td>\n      <td>0.301020</td>\n      <td>17196</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>American Pale Ale (APA)</td>\n      <td>0.167338</td>\n      <td>0.180754</td>\n      <td>0.173787</td>\n      <td>12647</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>Russian Imperial Stout</td>\n      <td>0.309647</td>\n      <td>0.404610</td>\n      <td>0.350816</td>\n      <td>10630</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>American Porter</td>\n      <td>0.223503</td>\n      <td>0.207952</td>\n      <td>0.215447</td>\n      <td>10161</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>American Double / Imperial Stout</td>\n      <td>0.361799</td>\n      <td>0.448238</td>\n      <td>0.400407</td>\n      <td>10104</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>American Amber / Red Ale</td>\n      <td>0.171532</td>\n      <td>0.228809</td>\n      <td>0.196073</td>\n      <td>9143</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Belgian Strong Dark Ale</td>\n      <td>0.386467</td>\n      <td>0.396476</td>\n      <td>0.391407</td>\n      <td>7491</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>Fruit / Vegetable Beer</td>\n      <td>0.259689</td>\n      <td>0.334737</td>\n      <td>0.292476</td>\n      <td>6886</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>American Strong Ale</td>\n      <td>0.241337</td>\n      <td>0.365169</td>\n      <td>0.290611</td>\n      <td>6408</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df.sort_values(by=['support'], ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Top 10 by f1-score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "data": {
      "text/plain": "                             beer_style  precision    recall        f1  \\\n96  Scottish Gruit / Ancient Herbed Ale   0.863946  0.718868  0.784758   \n69                  Japanese Rice Lager   0.665782  0.789308  0.722302   \n58                     Flanders Red Ale   0.840642  0.593208  0.695575   \n74                       Lambic - Fruit   0.539014  0.726476  0.618861   \n87                            Rauchbier   0.707993  0.547289  0.617354   \n1                American Adjunct Lager   0.499625  0.761640  0.603417   \n53                      Euro Pale Lager   0.519273  0.696912  0.595120   \n62                                 Gose   0.591304  0.523077  0.555102   \n67                      Irish Dry Stout   0.503618  0.577736  0.538137   \n76                          Light Lager   0.489424  0.466458  0.477665   \n\n    support  \n96      530  \n69      318  \n58     1325  \n74     2168  \n87      793  \n1      6121  \n53     3692  \n62      130  \n67     2650  \n76     2877  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>beer_style</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>96</th>\n      <td>Scottish Gruit / Ancient Herbed Ale</td>\n      <td>0.863946</td>\n      <td>0.718868</td>\n      <td>0.784758</td>\n      <td>530</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>Japanese Rice Lager</td>\n      <td>0.665782</td>\n      <td>0.789308</td>\n      <td>0.722302</td>\n      <td>318</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>Flanders Red Ale</td>\n      <td>0.840642</td>\n      <td>0.593208</td>\n      <td>0.695575</td>\n      <td>1325</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>Lambic - Fruit</td>\n      <td>0.539014</td>\n      <td>0.726476</td>\n      <td>0.618861</td>\n      <td>2168</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Rauchbier</td>\n      <td>0.707993</td>\n      <td>0.547289</td>\n      <td>0.617354</td>\n      <td>793</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>American Adjunct Lager</td>\n      <td>0.499625</td>\n      <td>0.761640</td>\n      <td>0.603417</td>\n      <td>6121</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>Euro Pale Lager</td>\n      <td>0.519273</td>\n      <td>0.696912</td>\n      <td>0.595120</td>\n      <td>3692</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>Gose</td>\n      <td>0.591304</td>\n      <td>0.523077</td>\n      <td>0.555102</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>Irish Dry Stout</td>\n      <td>0.503618</td>\n      <td>0.577736</td>\n      <td>0.538137</td>\n      <td>2650</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>Light Lager</td>\n      <td>0.489424</td>\n      <td>0.466458</td>\n      <td>0.477665</td>\n      <td>2877</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df.sort_values(by=['f1'], ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Top 10 by precision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "data": {
      "text/plain": "                             beer_style  precision    recall        f1  \\\n30                          Black & Tan   0.985714  0.146809  0.255556   \n13                 American Malt Liquor   0.928994  0.183626  0.306641   \n34                           Chile Beer   0.926316  0.176000  0.295798   \n96  Scottish Gruit / Ancient Herbed Ale   0.863946  0.718868  0.784758   \n58                     Flanders Red Ale   0.840642  0.593208  0.695575   \n91                                Sahti   0.756098  0.136564  0.231343   \n29                       Bière de Garde   0.716194  0.312682  0.435312   \n87                            Rauchbier   0.707993  0.547289  0.617354   \n36                       Czech Pilsener   0.685613  0.304536  0.421743   \n77                     Low Alcohol Beer   0.678571  0.075397  0.135714   \n\n    support  \n30      470  \n13      855  \n34      500  \n96      530  \n58     1325  \n91      227  \n29     1372  \n87      793  \n36     2535  \n77      252  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>beer_style</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30</th>\n      <td>Black &amp; Tan</td>\n      <td>0.985714</td>\n      <td>0.146809</td>\n      <td>0.255556</td>\n      <td>470</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>American Malt Liquor</td>\n      <td>0.928994</td>\n      <td>0.183626</td>\n      <td>0.306641</td>\n      <td>855</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Chile Beer</td>\n      <td>0.926316</td>\n      <td>0.176000</td>\n      <td>0.295798</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Scottish Gruit / Ancient Herbed Ale</td>\n      <td>0.863946</td>\n      <td>0.718868</td>\n      <td>0.784758</td>\n      <td>530</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>Flanders Red Ale</td>\n      <td>0.840642</td>\n      <td>0.593208</td>\n      <td>0.695575</td>\n      <td>1325</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>Sahti</td>\n      <td>0.756098</td>\n      <td>0.136564</td>\n      <td>0.231343</td>\n      <td>227</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Bière de Garde</td>\n      <td>0.716194</td>\n      <td>0.312682</td>\n      <td>0.435312</td>\n      <td>1372</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Rauchbier</td>\n      <td>0.707993</td>\n      <td>0.547289</td>\n      <td>0.617354</td>\n      <td>793</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Czech Pilsener</td>\n      <td>0.685613</td>\n      <td>0.304536</td>\n      <td>0.421743</td>\n      <td>2535</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>Low Alcohol Beer</td>\n      <td>0.678571</td>\n      <td>0.075397</td>\n      <td>0.135714</td>\n      <td>252</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df.sort_values(by=['precision'], ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Top 10 by recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "data": {
      "text/plain": "                             beer_style  precision    recall        f1  \\\n69                  Japanese Rice Lager   0.665782  0.789308  0.722302   \n1                American Adjunct Lager   0.499625  0.761640  0.603417   \n74                       Lambic - Fruit   0.539014  0.726476  0.618861   \n96  Scottish Gruit / Ancient Herbed Ale   0.863946  0.718868  0.784758   \n53                      Euro Pale Lager   0.519273  0.696912  0.595120   \n58                     Flanders Red Ale   0.840642  0.593208  0.695575   \n67                      Irish Dry Stout   0.503618  0.577736  0.538137   \n87                            Rauchbier   0.707993  0.547289  0.617354   \n62                                 Gose   0.591304  0.523077  0.555102   \n12                         American IPA   0.180058  0.511835  0.266400   \n\n    support  \n69      318  \n1      6121  \n74     2168  \n96      530  \n53     3692  \n58     1325  \n67     2650  \n87      793  \n62      130  \n12    23406  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>beer_style</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>69</th>\n      <td>Japanese Rice Lager</td>\n      <td>0.665782</td>\n      <td>0.789308</td>\n      <td>0.722302</td>\n      <td>318</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>American Adjunct Lager</td>\n      <td>0.499625</td>\n      <td>0.761640</td>\n      <td>0.603417</td>\n      <td>6121</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>Lambic - Fruit</td>\n      <td>0.539014</td>\n      <td>0.726476</td>\n      <td>0.618861</td>\n      <td>2168</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Scottish Gruit / Ancient Herbed Ale</td>\n      <td>0.863946</td>\n      <td>0.718868</td>\n      <td>0.784758</td>\n      <td>530</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>Euro Pale Lager</td>\n      <td>0.519273</td>\n      <td>0.696912</td>\n      <td>0.595120</td>\n      <td>3692</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>Flanders Red Ale</td>\n      <td>0.840642</td>\n      <td>0.593208</td>\n      <td>0.695575</td>\n      <td>1325</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>Irish Dry Stout</td>\n      <td>0.503618</td>\n      <td>0.577736</td>\n      <td>0.538137</td>\n      <td>2650</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Rauchbier</td>\n      <td>0.707993</td>\n      <td>0.547289</td>\n      <td>0.617354</td>\n      <td>793</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>Gose</td>\n      <td>0.591304</td>\n      <td>0.523077</td>\n      <td>0.555102</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>American IPA</td>\n      <td>0.180058</td>\n      <td>0.511835</td>\n      <td>0.266400</td>\n      <td>23406</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df.sort_values(by=['recall'], ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save objects for production"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "path = models_dir / f'{artefact_prefix}_model'\n",
    "torch.save(model, path.with_suffix('.torch'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create pipe object\n",
    "\n",
    "This is for transforming the input prior to prediction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "data": {
      "text/plain": "['D:\\\\git\\\\assignment_2\\\\models\\\\2_pytorch_pipe.sav']"
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X_train, X_val, X_test])\n",
    "prod_pipe = create_preprocessing_pipe(X)\n",
    "\n",
    "path = models_dir / f'{artefact_prefix}_pipe'\n",
    "dump(prod_pipe, path.with_suffix('.sav'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save `LabelEncoder`\n",
    "\n",
    "This is required to get back the name of the name of the `beer_style`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "data": {
      "text/plain": "['D:\\\\git\\\\assignment_2\\\\models\\\\2_pytorch_label_encoder.sav']"
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = models_dir / f'{artefact_prefix}_label_encoder'\n",
    "dump(le, path.with_suffix('.sav'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "adsi_ass_2",
   "language": "python",
   "display_name": "adsi_ass_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}